---
  title: "Opiniones apps Play Store (kaggle) Taller1"
author: "Reinier Mujica"
date: "1 de marzo de 2019"
output: 
  html_document: 
  number_sections: yes
toc: yes
---
  
```{r echo = FALSE}
library(knitr)
opts_chunk$set(message = FALSE, warning = FALSE, cache = TRUE)
options(width = 100, dplyr.width = 100)
library(ggplot2)
theme_set(theme_light())
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd('d:/MADM/Aplicacion de Mineria de Dades y tex industria del turisme/task1_mining_barcelona/')
```


```{r echo=FALSE}
library(stringr)       #Paquete para manipular la data
library(dplyr)         #Paquete para manipular datos
library(caTools)       #Paquete para subdividir la muestra
library(rpart)         #Paquete para el an?lisis de ?rboles"
library(rpart.plot)    #Paquete para el an?lisis de ?rboles"
library(randomForest)  #Paquete para el an?lisis de random forests"
library(mice)          #Contiene funciones para imputar valores perdidos
library(caret)         #Para calcular indicadores tales como R cuadrado
library(modelr)        #Provee funciones de ayuda para calcular estadisticos relacionados con modelos de regresion
library(broom)         #Crea data frame para mostrar estadisticos
library(ggplot2)       #Contine funciones para la visualizaci?n de datos en mapas
library(ggmap)

# Para usar los mapas de Google, necesitamos cargar la siguiente libreria, y luego instalar la versi?n de ggmap desde GitHub

# library(devtools)
# devtools::install_github("dkahle/ggmap")
# devtools::install_github("hadley/ggplot2")

```

## Guardando la Api key de Google
```{r echo=FALSE}
register_google(key = Sys.getenv("GOOGLE_MAPS_KEY"))
has_google_key()
```

## Cargamos los datos de Barcelona para el análisis
```{r echo=FALSE}
mll_data = read.csv("listings.csv", stringsAsFactors = TRUE, header = TRUE, sep = ",", encoding = "UTF-8")
```

## Limpiamos los datos
```{r echo=FALSE}
str_trim(mll_data$neighbourhood_cleansed, side=c("both"))
mll_data$price=as.numeric(gsub("\\$","",mll_data$price))
```

## Ahora, centremos la atencion en Barcelona y analicemos la ubicación y los precios

### Definiremos los datos que queremos representar en el mapa: La densidad de las propiedades en Airbnb
```{r}
map_data = mll_data[(mll_data$neighbourhood_cleansed == "el Raval"), ]
```

## Obtenemos en mapa de Barcelona
```{r}
MapStamen = qmap("barcelona", source = "stamen", zoom = 14, color = "bw")

MapGoogle=ggmap(
  ggmap = get_map(
    "Barcelona",
    zoom = 14, scale = "auto",
    maptype = "terrain",
    source = "google"),
  extent = "device",
  legend = "topright"
)
```

## Ubiquemos la información de la ubicación de las propiedades en el mapa
```{r}
MapGoogle + geom_point(data = map_data, aes(x = longitude, y = latitude), colour = "blue", size = 2, alpha = 0.25)
```

## Ubiquemos la información de la ubicación de las propiedades en el mapa por tipo de habitación
```{r}
MapGoogle + geom_point(data = map_data, aes(x = longitude, y = latitude), colour = "blue", size = 1, alpha = 1) +
  facet_wrap(~room_type)
```

## Creemos un mapa que muestre las zonas de Barcelona y las intensidades, según el precio
```{r}
bar_circle_size = 0.010 

MapGoogle + geom_point(data = map_data, aes(x = longitude, y = latitude), colour = "red", size = map_data$price*bar_circle_size, alpha = 0.5)
```


## Podemos usar un mapa para mostrar las intensidades, según la ubicación:
```{r}
MapGoogle +
  stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level..),
                 size = 1, data = map_data, geom = "polygon")

```

## Podemos extender el análisis para el caso de Barcelona
```{r}
MapGoogle=ggmap(
  ggmap = get_map(
    "Barcelona",
    zoom = 13, scale = "auto",
    maptype = "terrain",
    source = "google"),
  extent = "device",
  legend = "topright"
)

MapGoogle +
  stat_density2d(aes(x = longitude, y = latitude, fill = ..level.., alpha = ..level..),
                 size = 2, data = mll_data, geom = "polygon")
```

## Crearemos un mapa que muestre las zonas de Barcelona y las intensidades, según el precio
```{r}
mll_circle_size = 0.005 

MapGoogle + geom_point(data = mll_data, aes(x = longitude, y = latitude), colour = "red", size = mll_data$price*mll_circle_size, alpha = 0.5)
```


## Descripción de los datos antes de ajustar un modelo de regresión lineal que prediga el precio
## Examinamos la variable precios
```{r}
hist(mll_data$price)
mean(mll_data$price, na.rm = TRUE)
```

## El precio puede diferir dependiendo de la localidad. Podemos verificarlo a continuación
```{r echo=FALSE}
tapply(mll_data$price, mll_data$neighbourhood_cleansed, mean, na.rm = TRUE)

#Alternativamente
aggregate(price ~ neighbourhood_cleansed, data=mll_data, FUN=mean)
table(mll_data$property_type)
```
## Podemos examinar el precio según el tipo de propiedad
## Examinemos la asociacion entre precios y los evaluaciones de los consumidores
```{r}
aggregate(price ~ property_type, data=mll_data, FUN=mean)

aggregate(price ~ review_scores_value, data=mll_data, FUN=mean)
cor(mll_data$price, mll_data$review_scores_value, use="pairwise.complete.obs")
cor(mll_data$price, mll_data$review_scores_rating, use="pairwise.complete.obs")
aggregate(price ~ review_scores_rating, data=mll_data, FUN=mean)
```

## Ajustemos un modelo lineal de regresión para predecir el precio
## Crearemos la muestra de entrenamiento y de prueba
```{r}
spl = sample.split(mll_data$price, 0.8)
train = subset(mll_data, spl == TRUE)
test  = subset(mll_data, spl == FALSE)

mean(train$price, na.rm = TRUE)
mean(test$price, na.rm = TRUE)
```

## Ajustamos el modelo
```{r}
model_lm = lm(price ~ bedrooms + review_scores_value + number_of_reviews + square_feet + longitude + latitude, data=train)
summary(model_lm)
```

## Calculemos el Error Cuadrado Medio
```{r}
predict_lm = predict(model_lm, newdata = test)
MSE_lm = mean((predict_lm - test$price)^2, na.rm = TRUE)
MSE_lm

data.frame( R2 = R2(predict_lm, test$price, na.rm = TRUE),
            RMSE = RMSE(predict_lm, test$price, na.rm = TRUE),
            MAE = MAE(predict_lm, test$price, na.rm = TRUE))
```

## Examinemos la validación cruzada
## Imputaremos los valores NA de las variables numericas. No imputaremos dichos valores en el caso de la longitud y latitud
```{r}
mice_mod = mice(mll_data[, names(mll_data) %in% c("price", "bedrooms", "review_scores_value", "number_of_reviews", "square_feet" )], method = 'pmm', seed = 500)
mice_output = complete(mice_mod)
```

## Seleccionaremos los datos para el análisis, considerando la data con los valores imputados y las variables donde no se ha hecho tal imputacion
```{r}
covar=subset(mll_data, select=c("longitude", "latitude", "cancellation_policy"))
data_reg=cbind(covar, mice_output)
set.seed(1991) 
train.control = trainControl(method = "cv", number = 10)
```

## Entrenemos un modelo de regresion lineal
```{r}
model_vc_ols = train(price ~ bedrooms + review_scores_value + number_of_reviews + square_feet + longitude + latitude + cancellation_policy, data = data_reg, method = "lm", trControl = train.control)
print(model_vc_ols)
```

## Veamos si modelos alternativos pueden mejorar la prediccion. En primer lugar, probemos con una regresion de arbol
```{r}
model_cart = rpart(price ~ bedrooms + review_scores_value + number_of_reviews + square_feet + longitude + latitude + cancellation_policy, data=train, method = "anova", na.action = na.omit)
```

## Calculemos el Error Cuadrado Medio
```{r}
predict_cart = predict(model_cart, newdata = test)
MSE_cart = mean((predict_cart-test$price)^2, na.rm = TRUE)
MSE_cart
```

## Calculemos medidas alternativas, como el Error Absoluto Medio (MAE) o el R cuadrado o la Raíz de la Desviación Cuadrática Media (RMSE)
```{r}
data.frame( R2 = R2(predict_cart, test$price, na.rm = TRUE),
            RMSE = RMSE(predict_cart, test$price, na.rm = TRUE),
            MAE = MAE(predict_cart, test$price, na.rm = TRUE))
```

## Consideremos la validacion cruzada
```{r}
model_vc_tree = train(price ~ bedrooms + review_scores_value + number_of_reviews + square_feet + longitude + latitude + cancellation_policy, data = data_reg, method = "rpart", trControl = train.control)
print(model_vc_tree)
```

## Podemos dibujar el arbol
```{r}
prp(model_cart)
```

## Ahora, probemos con un Random Forest Model
```{r}
model_rf = randomForest(price ~ bedrooms + review_scores_value + number_of_reviews + square_feet + longitude + latitude + cancellation_policy, data=train, importance= TRUE, method = "anova", na.action = na.omit)
model_rf

predict_rf = predict(model_rf, ntree=4, newdata=test)
MSE_rf = mean((predict_rf-test$price)^2,na.rm = TRUE)
MSE_rf
```

## Calculemos medidas alternativas, como el Error Absoluto Medio (MAE) o el R cuadrado o la Raíz de la Desviación Cuadrática Media (RMSE)
```{r}
predictions_rf = predict(model_rf, test)

data.frame( R2 = R2(predict_rf, test$price, na.rm = TRUE),
            RMSE = RMSE(predict_rf, test$price, na.rm = TRUE),
            MAE = MAE(predict_rf, test$price, na.rm = TRUE))
```

## Consideremos la validacion cruzada
```{r}
model_vc_rf = train(price ~ bedrooms + review_scores_value + number_of_reviews + square_feet + longitude + latitude + cancellation_policy, data = data_reg, method = "rf", trControl = train.control)
print(model_vc_rf)

plot(model_rf)
```

## Grafico importancia de las variables
```{r}
varImpPlot(model_rf, sort=TRUE, main="Importancia", n.var=5)
```

#Tabla con la importancia de las variables
```{r}
var.imp=data.frame(importance(model_rf, type=2))
var.imp$Variables=row.names(var.imp)
var.imp[order(var.imp$IncNodePurity, decreasing = TRUE),]
```
